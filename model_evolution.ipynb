{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from evolution import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuremat = np.load('data/training_data/featurematrix.npy')\n",
    "time_to_failure_vec = np.load('data/training_data/time_to_failure.npy')\n",
    "testmat = np.load('data/test_processed/featurematrix_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = np.random.choice(np.arange(len(time_to_failure_vec)),size=int(len(time_to_failure_vec)*.9),replace=False)\n",
    "validationset = list(set(np.arange(len(time_to_failure_vec)))-set(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainmat = featuremat[trainset,:]\n",
    "validationmat = featuremat[validationset,:]\n",
    "\n",
    "time_to_failure_train = time_to_failure_vec[trainset]\n",
    "time_to_failure_validation = time_to_failure_vec[validationset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(trainmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainmat_scale = scaler.transform(trainmat)\n",
    "validationmat_scale = scaler.transform(validationmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generations = 100\n",
    "pop_size = 100\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "num_all_features = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for i in range(pop_size):\n",
    "    model_list.append(model({np.random.randint(num_all_features)},[np.random.randint(1,17)],[0],num_all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_list,trainmat,validationmat,model_ind):\n",
    "    \n",
    "    trainmat_use = trainmat[:,list(model_list[model_ind].featureset)]\n",
    "    validationmat_use = validationmat[:,list(model_list[model_ind].featureset)]\n",
    "\n",
    "    m = model_list[model_ind].build()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr=0.1,decay=.1)\n",
    "    m.compile(optimizer=opt,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_absolute_error'])\n",
    "    hist = m.fit(trainmat_use, \n",
    "          time_to_failure_train, \n",
    "          validation_data=(validationmat_use,time_to_failure_validation), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size,\n",
    "          verbose=0\n",
    "         )\n",
    "        \n",
    "    loss = hist.history['val_mean_absolute_error'][-1]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 finished, 167.755 sec, average loss nan, average loss of survivors 5.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/djustus/anaconda3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 finished, 165.772 sec, average loss nan, average loss of survivors 4.817\n",
      "Generation 2 finished, 167.404 sec, average loss 185.046, average loss of survivors 4.570\n",
      "Generation 3 finished, 173.420 sec, average loss 5095626.634, average loss of survivors 4.620\n",
      "Generation 4 finished, 179.478 sec, average loss 9829.025, average loss of survivors 4.137\n",
      "Generation 5 finished, 188.623 sec, average loss nan, average loss of survivors 3.588\n",
      "Generation 6 finished, 168.147 sec, average loss 875570.951, average loss of survivors 3.119\n",
      "Generation 7 finished, 172.553 sec, average loss 4.078, average loss of survivors 2.378\n",
      "Generation 8 finished, 177.523 sec, average loss 3.228, average loss of survivors 2.256\n",
      "Generation 9 finished, 174.496 sec, average loss 2.996, average loss of survivors 2.255\n",
      "Generation 10 finished, 169.309 sec, average loss 3.348, average loss of survivors 2.255\n",
      "Generation 11 finished, 177.362 sec, average loss 3.243, average loss of survivors 2.255\n",
      "Generation 12 finished, 2082.910 sec, average loss 3.384, average loss of survivors 2.255\n",
      "Generation 13 finished, 331.586 sec, average loss 3.207, average loss of survivors 2.255\n",
      "Generation 14 finished, 171.315 sec, average loss 3.102, average loss of survivors 2.255\n",
      "Generation 15 finished, 180.141 sec, average loss 3.242, average loss of survivors 2.255\n",
      "Generation 16 finished, 180.946 sec, average loss 3.418, average loss of survivors 2.255\n",
      "Generation 17 finished, 189.515 sec, average loss nan, average loss of survivors 2.255\n",
      "Generation 18 finished, 187.195 sec, average loss 3.171, average loss of survivors 2.255\n"
     ]
    }
   ],
   "source": [
    "loss = np.zeros([generations,pop_size])\n",
    "models_employed = []\n",
    "for gen in range(generations):\n",
    "    t = time.time()\n",
    "    \n",
    "    models_employed.append(model_list) \n",
    "    \n",
    "    loss_generation = Parallel(n_jobs=num_cores)(\n",
    "            delayed(train_model)(model_list,trainmat,validationmat,model_ind) for model_ind in range(pop_size)\n",
    "    )\n",
    "    loss[gen,:] = loss_generation\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "        \n",
    "    live = np.argsort(loss[gen,:])[0:int(pop_size/2)]\n",
    "    \n",
    "    model_list2 = []\n",
    "    for index in live:\n",
    "        model_list2.append(model_list[index])\n",
    "        m = copy.deepcopy(model_list[index])\n",
    "        m.mutate()\n",
    "        model_list2.append(m)\n",
    "\n",
    "    model_list = model_list2\n",
    "\n",
    "    print('Generation %d finished, %.3f sec, average loss %.3f, average loss of survivors %.3f' \n",
    "          %(gen, time.time()-t, np.mean(loss[gen,:]), np.mean(loss[gen,live])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(models_employed[9][i].num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

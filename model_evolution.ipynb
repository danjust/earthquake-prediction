{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from evolution import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuremat = np.load('data/training_data/featurematrix_v2.npy')\n",
    "time_to_failure_vec = np.load('data/training_data/time_to_failure.npy')\n",
    "testmat = np.load('data/test_processed/featurematrix_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = np.random.choice(np.arange(len(time_to_failure_vec)),size=int(len(time_to_failure_vec)*.9),replace=False)\n",
    "validationset = list(set(np.arange(len(time_to_failure_vec)))-set(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainmat = featuremat[trainset,:]\n",
    "validationmat = featuremat[validationset,:]\n",
    "\n",
    "time_to_failure_train = time_to_failure_vec[trainset]\n",
    "time_to_failure_validation = time_to_failure_vec[validationset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(trainmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainmat_scale = scaler.transform(trainmat)\n",
    "validationmat_scale = scaler.transform(validationmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generations = 500\n",
    "pop_size = 256\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "num_all_features = featuremat.shape[1]\n",
    "\n",
    "savepath = '/Users/djustus/workspace/earthquake/ckpt/'\n",
    "model_name = 'E3-256_all_features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create models with one hidden layer (with 1-64 units) each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for i in range(pop_size):\n",
    "    model_list.append(model(featureset={np.random.choice(range(num_all_features))},\n",
    "                            layerlist=[np.random.randint(1,64)],\n",
    "                            dropoutlist=[0],\n",
    "                            reg_constant=0.005,\n",
    "                            learning_rate=0.01,\n",
    "                            lr_decay=0.001,\n",
    "                            num_all_features=num_all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_list,trainmat,time_to_failure_train,validationmat,time_to_failure_validation,model_ind):\n",
    "    \n",
    "    trainmat_use = trainmat[:,list(model_list[model_ind].featureset)]\n",
    "    validationmat_use = validationmat[:,list(model_list[model_ind].featureset)]\n",
    "\n",
    "    m = model_list[model_ind].build()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr=model_list[model_ind].learning_rate,decay=model_list[model_ind].lr_decay)\n",
    "    m.compile(optimizer=opt,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_absolute_error'])\n",
    "    hist = m.fit(trainmat_use, \n",
    "          time_to_failure_train, \n",
    "          validation_data=(validationmat_use,time_to_failure_validation), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size,\n",
    "          verbose=0\n",
    "         )\n",
    "        \n",
    "    loss = hist.history['val_mean_absolute_error'][-1]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Train generation 0 completely.  \n",
    "Following generation 1: Train only mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-3acf18fbb16b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                                  \u001b[0mtime_to_failure_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                  model_ind) \n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#     loss_generation = [train_model(model_list,trainmat_scale,validationmat_scale,model_ind)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = np.zeros([generations,pop_size])\n",
    "born = np.zeros(pop_size)\n",
    "id_hist = [str(n) for n in range(pop_size)]\n",
    "\n",
    "models_employed = []\n",
    "while gen<generations:\n",
    "    gen+=1\n",
    "    num_features_gen = []\n",
    "    num_layers_gen = []\n",
    "    t = time.time()\n",
    "    \n",
    "    models_employed.append(model_list) \n",
    "    \n",
    "    for model_ind in range(pop_size):\n",
    "        num_features_gen.append(model_list[model_ind].num_features)\n",
    "        num_layers_gen.append(model_list[model_ind].num_layers)\n",
    "        \n",
    "    loss_generation = Parallel(n_jobs=num_cores)(\n",
    "            delayed(train_model)(model_list,\n",
    "                                 trainmat_scale,\n",
    "                                 time_to_failure_train,\n",
    "                                 validationmat_scale,\n",
    "                                 time_to_failure_validation,\n",
    "                                 model_ind) \n",
    "            for model_ind in range(int(pop_size/2),pop_size)\n",
    "    )\n",
    "#     loss_generation = [train_model(model_list,trainmat_scale,validationmat_scale,model_ind) \n",
    "#                        for model_ind in range(pop_size)]\n",
    "    loss_generation = [1e9 if np.isnan(val) else val for val in loss_generation]\n",
    "    \n",
    "    if gen==0:\n",
    "        loss_survivor = Parallel(n_jobs=num_cores)(\n",
    "            delayed(train_model)(model_list,\n",
    "                                 trainmat_scale,\n",
    "                                 time_to_failure_train,\n",
    "                                 validationmat_scale,\n",
    "                                 time_to_failure_validation,\n",
    "                                 model_ind) \n",
    "            for model_ind in range(0,int(pop_size/2))\n",
    "        )\n",
    "        loss_survivor = [1e9 if np.isnan(val) else val for val in loss_survivor]\n",
    "            \n",
    "    loss[gen,0:int(pop_size/2)] = loss_survivor\n",
    "    loss[gen,int(pop_size/2):pop_size] = loss_generation\n",
    "    \n",
    "    tf.keras.backend.clear_session()    \n",
    "        \n",
    "    survive = np.argsort(born)[int(pop_size/2):]\n",
    "    parent = np.argsort(loss[gen,:])[0:int(pop_size/2)]\n",
    "    best = parent[0]\n",
    "    \n",
    "    print('Generation %d finished, %.3f sec,\\n'\n",
    "          'average number of features %.1f, average number of layers %.1f, average loss %.3f, \\n'          \n",
    "          'best features %s, best number of layers %.1f, best loss %.3f'\n",
    "          %(gen, time.time()-t, \n",
    "            np.mean(num_features_gen), np.mean(num_layers_gen), np.mean(loss[gen,:]), \n",
    "            model_list[best].featureset, model_list[best].num_layers, loss[gen,best]))\n",
    "    \n",
    "    model_list2 = []\n",
    "    born2 = []\n",
    "    id_hist2 = []\n",
    "    loss_survivor = []\n",
    "    for model_ind in survive:\n",
    "        model_list2.append(model_list[model_ind])\n",
    "        loss_survivor.append(loss[gen,model_ind])\n",
    "        born2.append(born[model_ind])\n",
    "        id_hist2.append(id_hist[model_ind])\n",
    "    for model_ind in parent:\n",
    "        mutation = copy.deepcopy(model_list[model_ind])\n",
    "        mutation.mutate()\n",
    "        model_list2.append(mutation)\n",
    "        born2.append(time.time())\n",
    "        id_hist2.append(id_hist[model_ind]+','+str(model_ind))\n",
    "        \n",
    "    born = born2\n",
    "    model_list = model_list2\n",
    "    id_hist = id_hist2\n",
    "    with open(os.path.join(savepath,'model_list_%s_gen%d.pkl' %(model_name,gen)),'wb') as fn:\n",
    "        pickle.dump(model_list,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10, 26, 14}\n",
      "{10, 12, 31}\n",
      "{11, 10, 26}\n",
      "{10, 26, 12}\n",
      "{3, 10, 26, 12}\n",
      "{26, 10, 35, 12}\n",
      "{10, 26, 12}\n",
      "{10, 26, 12}\n",
      "{35, 10, 26, 12}\n",
      "{25, 10, 12}\n",
      "{10, 3, 36}\n",
      "{10, 12}\n",
      "{32, 10, 12, 26, 29}\n",
      "{35, 10, 26, 12}\n",
      "{10, 12}\n",
      "{10, 11, 31}\n",
      "{33, 4, 10, 12, 20}\n",
      "{10, 12}\n",
      "{26, 10, 35, 12}\n",
      "{35, 10, 26, 12}\n",
      "{8, 10, 11}\n",
      "{25, 10, 12}\n",
      "{11, 2, 10}\n",
      "{26, 10, 35, 12}\n",
      "{10, 12}\n",
      "{10, 26, 11}\n",
      "{10, 12, 13}\n",
      "{32, 10, 12, 26, 29}\n",
      "{10, 12}\n",
      "{2, 10, 11}\n",
      "{10, 12}\n",
      "{10, 11, 31, 23}\n",
      "{10, 26, 36}\n",
      "{10, 12}\n",
      "{32, 10}\n",
      "{10, 26, 11}\n",
      "{32, 10, 12}\n",
      "{10}\n",
      "{32, 10}\n",
      "{10, 11}\n",
      "{32, 10, 30}\n",
      "{32, 10, 30}\n",
      "{10, 3, 36}\n",
      "{10}\n",
      "{32, 10, 30}\n",
      "{32, 10, 30}\n",
      "{32, 10, 23}\n",
      "{32, 10}\n",
      "{9, 10, 30}\n",
      "{32, 1, 10, 15}\n",
      "{10}\n",
      "{32, 10, 3}\n",
      "{10, 12}\n",
      "{32, 10}\n",
      "{10, 30}\n",
      "{30}\n",
      "{32, 10, 23}\n",
      "{10, 26}\n",
      "{10, 12}\n",
      "{32, 10}\n",
      "{32, 10, 30}\n",
      "{10}\n",
      "{32, 10, 30}\n",
      "{27, 10, 18}\n",
      "{12}\n",
      "{10, 30}\n",
      "{9, 10, 19}\n",
      "{32, 1, 37, 10, 30}\n",
      "{32, 10}\n",
      "{10, 30}\n",
      "{3}\n",
      "{10, 30}\n",
      "{10, 35, 30}\n",
      "{32, 10}\n",
      "{8, 10}\n",
      "{32, 1, 10}\n",
      "{32, 10, 30}\n",
      "{10}\n",
      "{10}\n",
      "{24, 10}\n",
      "{32, 10}\n",
      "{32}\n",
      "{32, 10, 30}\n",
      "{32, 10, 30}\n",
      "{10, 3}\n",
      "{10, 26}\n",
      "{10, 2, 6}\n",
      "{26, 10, 35, 12}\n",
      "{10, 18}\n",
      "{10, 30}\n",
      "{32, 10}\n",
      "{32, 10}\n",
      "{32, 10, 30}\n",
      "{32, 10, 30}\n",
      "{10}\n",
      "{10}\n",
      "{16, 33, 10, 35}\n",
      "{33, 10}\n",
      "{25, 10}\n",
      "{33, 10}\n",
      "{10, 30}\n",
      "{19, 10, 2}\n",
      "{10, 11}\n",
      "{10, 2}\n",
      "{10, 11}\n",
      "{0, 10, 30}\n",
      "{32, 30}\n",
      "{32, 10, 31}\n",
      "{24}\n",
      "{24, 10}\n",
      "{10, 19, 30, 23}\n",
      "{10, 2}\n",
      "{32, 10}\n",
      "{32, 30}\n",
      "{10, 26}\n",
      "{10}\n",
      "{10, 2}\n",
      "{10, 26, 12}\n",
      "{26, 10, 19}\n",
      "{10, 19, 30}\n",
      "{10}\n",
      "{32, 10, 30}\n",
      "{16, 33, 10, 35}\n",
      "{10, 26}\n",
      "{10, 37}\n",
      "{9, 10, 34}\n",
      "{10, 29}\n",
      "{9, 10, 34}\n",
      "{10, 26, 12, 14}\n",
      "{10, 12, 31}\n",
      "{26, 10, 3, 12}\n",
      "{33, 4, 10, 12, 20}\n",
      "{10, 26, 12}\n",
      "{11, 10, 26}\n",
      "{10, 26, 12}\n",
      "{26, 12}\n",
      "{10, 26, 12}\n",
      "{26, 10, 35, 12}\n",
      "{10, 26, 12}\n",
      "{35, 26, 10, 12}\n",
      "{10, 12}\n",
      "{32, 10, 12, 26, 29}\n",
      "{10, 3, 36}\n",
      "{32, 10, 12, 26, 29}\n",
      "{35, 26, 10, 12}\n",
      "{10, 3, 36}\n",
      "{25, 10, 12}\n",
      "{35, 10, 26, 12}\n",
      "{10, 12}\n",
      "{32, 10, 12, 26, 29}\n",
      "{26, 10, 35, 12}\n",
      "{32, 10, 12}\n",
      "{33, 10, 12}\n",
      "{10, 12}\n",
      "{10, 11, 21, 31}\n",
      "{35, 26, 10, 12}\n",
      "{26, 10, 35, 12}\n",
      "{8, 11}\n",
      "{2, 10}\n",
      "{26, 10, 35, 12}\n",
      "{10, 12, 13}\n",
      "{25, 10, 12, 17}\n",
      "{10, 12}\n",
      "{10, 12}\n",
      "{26, 11}\n",
      "{8, 10, 11}\n",
      "{10, 26, 36}\n",
      "{10, 3, 36}\n",
      "{10, 11, 31, 23}\n",
      "{10, 2, 6}\n",
      "{10, 26, 36}\n",
      "{26, 10, 35, 12}\n",
      "{10, 12}\n",
      "{10, 26, 12}\n",
      "{10, 12}\n",
      "{10}\n",
      "{10, 26, 11}\n",
      "{32, 10, 23}\n",
      "{10, 37}\n",
      "{9, 10, 30}\n",
      "{0, 10, 30}\n",
      "{32, 10, 12}\n",
      "{32, 1, 10, 30}\n",
      "{10}\n",
      "{32, 10, 31}\n",
      "{10}\n",
      "{10, 11, 28}\n",
      "{35, 10, 12, 14, 26}\n",
      "{32, 24, 10, 30}\n",
      "{32, 1, 10, 15}\n",
      "{26, 10, 11}\n",
      "{32, 10, 3}\n",
      "{10, 2}\n",
      "{11, 2, 10}\n",
      "{32, 10, 30}\n",
      "{32, 1, 10}\n",
      "{10, 28}\n",
      "{32, 10}\n",
      "{10, 11}\n",
      "{10, 12, 20}\n",
      "{32, 10, 28, 23}\n",
      "{32, 10}\n",
      "{32, 1, 10}\n",
      "{10, 12, 21}\n",
      "{10, 30}\n",
      "{32, 10, 30}\n",
      "{32}\n",
      "{10, 12}\n",
      "{32, 10}\n",
      "{10, 12, 13}\n",
      "{32, 10}\n",
      "{24, 10}\n",
      "{32, 10}\n",
      "{32, 10}\n",
      "{10, 27}\n",
      "{10, 18}\n",
      "{10, 35, 30}\n",
      "{9, 10, 34}\n",
      "{10, 12}\n",
      "{10, 30}\n",
      "{11, 10, 26}\n",
      "{9, 10, 19}\n",
      "{10, 3}\n",
      "{10, 12, 31}\n",
      "{10, 30}\n",
      "{10, 11, 23, 31}\n",
      "{32, 10, 6}\n",
      "{32, 1, 10}\n",
      "{32, 10, 30}\n",
      "{10}\n",
      "{18, 10, 27}\n",
      "{10}\n",
      "{24, 10}\n",
      "{32, 10}\n",
      "{32, 10}\n",
      "{10}\n",
      "{32, 10}\n",
      "{10, 3}\n",
      "{10}\n",
      "{32}\n",
      "{32, 8, 10}\n",
      "{32, 10, 30}\n",
      "{32, 10, 30}\n",
      "{10, 2}\n",
      "{10, 30}\n",
      "{10, 34}\n",
      "{24, 10}\n",
      "{33, 10}\n",
      "{10, 30}\n",
      "{2, 10, 19, 5}\n",
      "{33, 10}\n",
      "{10, 30}\n",
      "{10, 26}\n",
      "{10}\n",
      "{10, 11}\n",
      "{32, 10, 35, 30}\n"
     ]
    }
   ],
   "source": [
    "for i in range(pop_size):\n",
    "    print(model_list[i].featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmin(loss[gen-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model=model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.layerlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = best_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainmat_use = trainmat[:,list(best_model.featureset)]\n",
    "validationmat_use = validationmat[:,list(best_model.featureset)]\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.01,decay=.1)\n",
    "m.compile(optimizer=opt,\n",
    "          loss='mean_squared_error',\n",
    "          metrics=['mean_absolute_error'])\n",
    "hist = m.fit(trainmat_use,\n",
    "             time_to_failure_train, \n",
    "             validation_data=(validationmat_use,time_to_failure_validation), \n",
    "             epochs=1000, \n",
    "             batch_size=batch_size\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurecount = np.zeros(num_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(256):\n",
    "    for f in model_list[i].featureset:\n",
    "        featurecount[f] = featurecount[f]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b3816d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(38),featurecount)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
